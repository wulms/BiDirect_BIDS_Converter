//settings section start
:author: Niklas Wulms
:email: wulms@uni-muenster.de
:encoding: utf-8
:lang: en
:toc: macro
:toc-title: Table of Content
:toclevels: 2
:numbered:
:includes: includes
:imagesdir: images
:figure-caption: Figure
:xrefstyle: short
:table-caption: Table
// settings section stop

= To-Dos & Upcoming ideas: Dev-Script storing stuff to work on

NOTE: Only for development purposes!

'''

toc::[]

== Support of Anonymization

* *optional* "anonymization.csv"
** for changing subject ids - left(old name), right (new name)
** anonymization using pydeface or fsl_deface for sharing anonymized (header + image) files

== Consistent debugging information

== Docker integration

=== The algorithm works as described below:

=== Requirements

* a study folder as root directory
* a folder named DICOM, with a folder for each session (your session IDs: eg. Baseline, FollowUp1, etc)
* in these folders the subjects of that session, containing the DICOM folders
* you have to think about your subject nomenclature - if you have a naming scheme (e.g. 5 digits, the first on coding the group), other naming conventions are set by regular expressions later

=== Container start

* The container is started using the command "docker run - ….. " (coming).
Here your study folder (containing the DICOM folder) is mounted into the container and Docker can write files to it.

=== Output folders and user interaction folders

* folder creation:
* *BIDS/sourcedata* - the output folder for your dataset in BIDS format
** _dont.txt_ - change to _do.txt_ AFTER checking with the *Dashboard* and *user diagnostics* that your settings are working.
* *NII_temp* - write out folder for the anonymized dcm2niix converted files and headers. Do NOT delete these files. Each session is a folder, containing all subjects folders. Take care, it is dependent on the right subject nomenclature in the _user_settings/pattern_remove.txt_). The files are not in BIDS format but converted to NIIGZ.
* *NII_headers* - write out folder only for dicom headers (same structure as NII_temp), but these headers are NOT anonymized. It is used for plausibility checks (ID, gender, birthdate, weight, acquisition date).
* *Export_Cooperation*
** _export_template_ file, change the information and rename the file to enable BIDS export for a cooperation partner. _Export_output_BIDS_ folder is saved here.
* *user_information* - write out folder for information files regarding the renaming and conversion procedures
* *user_diagnostics* - write out folder for diagnostics
* *user_settings* - write out folder for the files, that you have to edit manually in a spreadsheet. All these files will be checked for not assigned values and inconsistencies, so that the code inhibits the further processing steps. If you have e.g. subjects, that does not fit into your subject regex the code aborts - this is functionality to keep your output data clean and affects all "user_settings" files. Debugging messages will be implemented!
** _pattern_remove.txt_ - is created before the dcm2niix conversion runs. Script aborts here, if the information below is not overwritten.
** subjects: [:digit:]{5} - regular expression indicating 5 digits for the subject name. Find out how your naming convention for the subjects is. If you have subjects-ids like AB01 you can set this regex: [:alpha:]{2}[:digit:]{2}. For other setups look into the "stringr Cheat Sheet", page 2 - hostet by RStudio.
** group: regex, where the group id in the filename is. In my case I can extract the first digit from the 5 digit subject id using [:digit:]{1}(?=[:digit:]{4}) - translated to &quot;extract the one digit, which is followed by 4 other digits. Please think about adding it to the filename, because further file selection is much easier.
** remove: Here you can add regex or absolute tags, that you want to remove from the foldername, e.g. ",BiDirect" in my case to have a clearly structured subject id.
** This file is checked every run, to identify the already processed output folders, but also to keep sure, that your nomenclature works.
** _BIDS_session_mapping.csv_ -
** Here you give your sessions a renaming nomenclature if needed (Baseline = 1, FollowUp = 2, or something else).
** This file is checked every run to identify new sessions.
** _BIDS_mapping.csv_ - This is the file, that needs the most work. You map each of the automatically identified sequences in your dataset to a BIDS Standard name (T1w, T2w, FLAIR, ect…). Do NOT add filename extensions (eg.".nii" or ".nii.gz"). They will be added automatically to add NII and JSON data to your BIDS dataset (requirement of BIDS). The right nomenclature also identifies the bids tags _anat/dwi/func_ based on your input data. If the detection is misleading just contact me!
Then you can label binary in the "relevant" column, which files are relevant (1) and not relevant (0) for you. This affects, which output you want to copy to the BIDS folder! Please check the diagnostics folder, if your mapping is correct. Here you can uncheck for instance Smartbrains or scanner-derived processings.
* *Dashboard* contains the rendered Dashboard if enabled, based on the extracted JSON information. Change _dont.txt_ to _do.txt_ if you want to enable the Dashboard. Only possible after the editing the _BIDS_mapping.csv_.

You see, that you only have to ineract with 3 scripts! If something is implausible, the tool will give you in future the exact filename, where something is missing.