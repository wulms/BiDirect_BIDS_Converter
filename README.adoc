//settings section start
:author: Niklas Wulms
:email: wulms@uni-muenster.de
:encoding: utf-8
:lang: en
:toc: macro
:toc-title: Table of Content
:toclevels: 2
:numbered:
:includes: includes
:imagesdir: images
:figure-caption: Figure
:xrefstyle: short
:table-caption: Table
// settings section stop


= BiDirect BIDS ConverteR
Niklas Wulms <wulms@uni-muenster.de>

image:https://zenodo.org/badge/195199025.svg[DOI,link=https://zenodo.org/badge/latestdoi/195199025]

[discrete]
toc::[]

'''

== Introduction

This tool is a project of my PhD.
It converts MRI data from DICOM to BIDS in three user-interactions (csv editings).
A folder containing your participants DICOMS is your input.
A BIDS specification dataset, that passes the BIDS-Validator your output.
I developed this tool on all the neuroimaging data of the BiDirect study (Institute of Epidemiology and Social Medicine, WWU, MÃ¼nster, Germany).

== Dear User - Read this first!

IMPORTANT: We want to give our best providing a good qualified easy-to-use tool for you all. +
Nevertheless, we need your help to find issues, bugs and so on because we are not able to find everything. +
If you find any bugs in current or future releases, please raise an https://github.com/wulms/BiDirect_BIDS_Converter/issues[issue here at GitHub]. +
We will try to figure out the problem as soon as possible.
You can help by putting everything you know, did, see into a new issue. +
 As more information you give us, as much faster we can fix the problems you have. +
This being said, we hope you enjoy the tool, and it helps you to do reproductive work quicker.

== Short tutorial:

TIP: If you need a detailed Step-by-Step tutorial how to work with the client, we recommend you to check this https://github.com/wulms/BiDirect_BIDS_Converter/wiki/Tutorial[Wiki-Tutorial-Page]

'''

This tool is a user-friendly tool to convert your dicom study data to BIDS. 
The following section will give you a quick start for using this tool.

IMPORTANT: It is required, that you have a structured naming convention on your folders, that contain the dicoms.

Main working goal is to run the following command over and over again until all issues are resolved.

.Start command from Terminal for Converter
[source,shell script]
----
Rscript --vanilla start_BIDS_ConverteR.R /home/path/study_data
----

[horizontal]
First Step:: Setup of subject info (subject-regex, group-regex)  & pattern_to_remove-regex - that removes redundant appendices from subject string

Second Step:: Setup of session info. +
Your naming scheme for the session, if different from the foldername. +
Conversion (lazy, automated, if settings above are plausible). +
nii + JSON (removal of sensitive information). +
JSON (containing all information for internal quality control)

Third Step:: Setup of sequence info. +
Identifies all sequence names. +
You have to name the sequences to BIDS standard. +
Set type (anat/dwi/func). +
Decide on relevance (0:no or 1:yes). +
The relevant sequences are copied to BIDS.

Fourth Step:: Copy2BIDS +
Copies relevant sequences to BIDS +
Will create:
* automated output based on dicom headers: *_participants.tsv/.json_*, *_TaskName.json_*
* template output of: *_study_description.json_*, *_README_* and *_CHANGES_*
** Edit these files, to fit to your study!

Last Step:: Check your dataset with https://bids-standard.github.io/bids-validator/[BIDS-Validator]

Result::
* User folder, where you see settings on session, sequence and subject information (subject-id and group-id).
* bids/sourcedata folder contains participants.tsv extracted from dicom header-info, and the other json files, needed for a valid BIDS dataset.
* You only need to customize these to your study/authors/grant/license.

== Tips on user Interaction

NOTE: Please use LibreOffice for native support. +
Microsoft Excel interprets input data already instead on relying on the csv structure.
So it has some problems in parsing the csv into spreadsheets and depends on local language and delimiter settings
There are settings on your system, that would enable the support of Excel on your computer.
https://support.ecwid.com/hc/en-us/articles/207100869-Import-export-CSV-files-to-Excel[Click on the link for information]

. Follow the statements of the script every time

. Edit the files correctly.

. user/settings/lut_study_info.csv - you need an exact match of the subject and group regex
** subject regex: "[:digit:]{5}" - translates to: 5 digits specify my subject id
** group regex: "[:digit:]{1}(?=[:digit:]{4})" - translates to: the first digit, before 4 digits come (in a total of 5 digits)
** pattern to remove simple: &quot;_your_study|_your_stdy|_yr_study|_your_study|_my_Study" - translates to: remove each occurrence of a string (splitted by "|&quot;&quot;)
** pattern to remove advanced: "_(your|yr|my)_(study|stdy|Study)"
** pattern to remove expert: "(?&lt;=[:digit:]{5})*" - translates to:

. user/settings/lut_sessions.csv - name your sessions

. user/settings/lut_sequences.csv - name your sequences to BIDS.
*_Please look into the BIDS specifications for further information on valid filenames._*

. customize the files (automated output) in the bids/sourcedata directory

=== File descriptions

* dataset_description.json - contains general information on your study (authors, grants, acknowledgement, licenses, etc.)

* README - contains general information on your study

* CHANGES - changelog of your files

* participants.tsv - automated extraction of parameters from the dicom header

* participants.json - describing the variables of the participants.tsv

* taskname_bold.jsons - multiple files, depending on functional scans
** on Philips data you have to calculate the Slice_Timing manually
** Chris Rorden gave some information
https://neurostars.org/t/heudiconv-no-extraction-of-slice-timing-data-based-on-philips-dicoms/2201/9[In this post] and  +
https://www.mccauslandcenter.sc.edu/crnl/tools/stc[On his website]


== General information

* I provided template files, that you have to edit manually.
I think, that this makes the use more easy for you.
* Everytime you start the Container all the above steps run.
If you have new subjects added to the *DICOM* folder, you maybe need to edit the new information in the _.csv files_ or the *user_settings* folder again.
The older information from before is kept.
If you delete the files, you need to set them up again, to get the process running.
* The implemented stops are only conducted, when manual editing is needed and a debug message is shown.
E.g. a new subject, session or sequence was identified.
* We implemented lazy processing, so that already converted files or extracted information is NOT extracted twice to enable functionality from the beginning of a study to the end.
* If something strange happens, delete every other folder than the DICOM folder and run the script again.

== Known issues

* Mainly based on misleading information/regex provided by the user on the BIDS standard
* Philips does not provide Slice-Timing information
* Issues, when you change LUT (look-up-table) information, e.g. "relevance" or "bids_sequence_id" of a sequence in an ongoing study.
* It is everytime safe to delete the "bids" and "nii_temp" directory, and start the script again
* If you delete the user-directory, all your manual settings are deleted!